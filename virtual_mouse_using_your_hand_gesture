import cv2
import mediapipe as mp
import pyautogui
import numpy as np

# Initialize mediapipe hands with handedness detection
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils

screen_width, screen_height = pyautogui.size()
cap = cv2.VideoCapture(0)

prev_loc_x, prev_loc_y = 0, 0
smoothening = 7

while True:
    success, img = cap.read()
    if not success:
        break

    img = cv2.flip(img, 1)  # mirror
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    result = hands.process(img_rgb)

    img_height, img_width, _ = img.shape

    if result.multi_hand_landmarks:
        hand_landmarks = result.multi_hand_landmarks[0]
        mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)

        # Get handedness (Left/Right)
        hand_label = result.multi_handedness[0].classification[0].label

        lm_list = []
        for id, lm in enumerate(hand_landmarks.landmark):
            x, y = int(lm.x * img_width), int(lm.y * img_height)
            lm_list.append((x, y))

        # Finger tips landmarks
        index_x, index_y = lm_list[8]
        thumb_x, thumb_y = lm_list[4]
        middle_x, middle_y = lm_list[12]

        # Draw circles for feedback
        cv2.circle(img, (index_x, index_y), 10, (255, 0, 255), cv2.FILLED)
        cv2.circle(img, (thumb_x, thumb_y), 10, (255, 0, 255), cv2.FILLED)
        cv2.circle(img, (middle_x, middle_y), 10, (255, 0, 255), cv2.FILLED)

        # Convert index finger position from webcam coords to screen coords
        screen_x = np.interp(index_x, (0, img_width), (0, screen_width))
        screen_y = np.interp(index_y, (0, img_height), (0, screen_height))

        # Smooth cursor movement
        curr_loc_x = prev_loc_x + (screen_x - prev_loc_x) / smoothening
        curr_loc_y = prev_loc_y + (screen_y - prev_loc_y) / smoothening

        # For left hand, move mouse as is
        # For right hand, mirror horizontally for natural movement
        if hand_label == "Left":
            pyautogui.moveTo(curr_loc_x, curr_loc_y)
        else:  # Right hand
            pyautogui.moveTo(screen_width - curr_loc_x, curr_loc_y)

        prev_loc_x, prev_loc_y = curr_loc_x, curr_loc_y

        # Calculate distances for clicks
        dist_thumb_index = np.hypot(thumb_x - index_x, thumb_y - index_y)
        dist_thumb_middle = np.hypot(thumb_x - middle_x, thumb_y - middle_y)

        # Left click: thumb + index finger close
        if dist_thumb_index < 40:
            pyautogui.click(button='left')
            cv2.circle(img, ((thumb_x + index_x) // 2, (thumb_y + index_y) // 2), 15, (0, 255, 0), cv2.FILLED)

        # Right click: thumb + middle finger close
        elif dist_thumb_middle < 40:
            pyautogui.click(button='right')
            cv2.circle(img, ((thumb_x + middle_x) // 2, (thumb_y + middle_y) // 2), 15, (0, 0, 255), cv2.FILLED)

    cv2.imshow("Virtual Mouse", img)

    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit
        break

cap.release()
cv2.destroyAllWindows()
